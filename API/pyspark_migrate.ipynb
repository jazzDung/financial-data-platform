{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace, col, lit, concat_ws\n",
    "from pathlib import Path\n",
    "from vnstock import *\n",
    "from pyspark.sql.types import StructType\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "pkg_resources.require(\"pandas==1.4.0\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "\n",
    "# Get ticker list\n",
    "tickers = Path(\"/home/jazzdung/Projects/financial-data-platform/Airflow/data/airflow/ticker/ticker.txt\").read_text()[1:-1].split(\"', '\")\n",
    "\n",
    "# Database info\n",
    "USERNAME = 'postgres'\n",
    "PASSWORD = '02092001'\n",
    "URL = \"jdbc:postgresql://localhost:5432/financialDataPlatform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read a table\n",
    "df = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", URL) \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"dbtable\", \"income_statement\") \\\n",
    "        .option(\"user\", USERNAME) \\\n",
    "        .option(\"password\", PASSWORD) \\\n",
    "        .load()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to table\n",
    "def data_to_db(df, table):\n",
    "    (df.write\n",
    "        .option(\"truncate\", \"true\")\n",
    "        .format('jdbc')\n",
    "        .options(\n",
    "            url=URL,\n",
    "            driver='org.postgresql.Driver',\n",
    "            dbtable=table,\n",
    "            user=USERNAME,\n",
    "            password=PASSWORD)\n",
    "        .mode('overwrite')\n",
    "        .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio(report_type, table):\n",
    "\n",
    "    '''\n",
    "    Use for cashflow, incomestatement, balancesheet, financialratio\n",
    "    '''\n",
    "\n",
    "    #Create blank dataframe\n",
    "    df = spark.createDataFrame([], StructType([]))\n",
    "\n",
    "    #Append each ticker's value\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            for i in range(2):     \n",
    "                       \n",
    "                if report_type in [\"cashflow\", \"incomestatement\", \"balancesheet\"]:\n",
    "                    data = requests.get('https://apipubaws.tcbs.com.vn/tcanalysis/v1/finance/{}/{}'.format(ticker, report_type), params={'yearly': i, 'isAll':'true'})\n",
    "                else:\n",
    "                    data = requests.get('https://apipubaws.tcbs.com.vn/tcanalysis/v1/finance/{}/financialratio?yearly={}&isAll={}'.format(ticker, i, True))\n",
    "                \n",
    "                rdd = spark.sparkContext.parallelize([data.text])\n",
    "                value = spark.read.json(rdd)\n",
    "                df = df.unionByName(value, allowMissingColumns=True)     \n",
    "        except Exception: \n",
    "            pass  \n",
    "    \n",
    "    #Clean\n",
    "    df = df.dropDuplicates([\"ticker\",\"year\",\"quarter\"])\n",
    "    df = df.orderBy(col(\"ticker\").asc(),col(\"year\").desc(), col(\"quarter\").desc())\n",
    "\n",
    "    #Write to db\n",
    "    data_to_db(df, table)\n",
    "    return df\n",
    "\n",
    "# test = get_ratio('incomestatement', 'incomestatement').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(rating_type, table):\n",
    "\n",
    "    '''\n",
    "    Use for general, business-model, business-operation, financial-health, valuation, financial-health\n",
    "    '''\n",
    "\n",
    "    #Create blank dataframe\n",
    "    df = spark.createDataFrame([], StructType([]))\n",
    "\n",
    "    #Append each ticker's value\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            url = 'https://apipubaws.tcbs.com.vn/tcanalysis/v1/rating/{}/' + rating_type + '?fType=TICKER'\n",
    "            data = requests.get(url.format(ticker))\n",
    "            rdd = spark.sparkContext.parallelize([data.text])\n",
    "            value = spark.read.json(rdd)\n",
    "\n",
    "            if rating_type == 'general':\n",
    "                value = value.drop(col('stockRecommend'))\n",
    "                \n",
    "            df = df.unionByName(value, allowMissingColumns=True)\n",
    "        except Exception: \n",
    "            pass  \n",
    "    \n",
    "    #Clean\n",
    "    df = df.dropDuplicates([\"ticker\"])\n",
    "    df = df.orderBy(col(\"ticker\").asc())\n",
    "\n",
    "    #Write to db\n",
    "    data_to_db(df, table)\n",
    "    return df\n",
    "\n",
    "# test = get_rating('general', 'general_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_time(df, column):\n",
    "    time_stamp = regexp_replace(col('tradingDate'), 'T', ' ')\n",
    "    time_stamp = regexp_replace(time_stamp, '\\.(.+)', '')\n",
    "    return df.withColumn(column, time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_history(start_date, end_date):\n",
    "    #Convert date to timestamp\n",
    "    fd = int(time.mktime(time.strptime(start_date, \"%Y-%m-%d\")))\n",
    "    td = int(time.mktime(time.strptime(end_date, \"%Y-%m-%d\")))\n",
    "\n",
    "    #Create blank dataframe\n",
    "    df = spark.createDataFrame([], StructType([]))\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data = requests.get('https://apipubaws.tcbs.com.vn/stock-insight/v1/stock/bars-long-term?ticker={}&type=stock&resolution=D&from={}&to={}'.format(ticker, fd, td)).json()\n",
    "            rdd = spark.sparkContext.parallelize(data['data'])\n",
    "            value = spark.read.json(rdd)\n",
    "            value = value.withColumn('ticker', lit(ticker))\n",
    "            df = df.unionByName(value, allowMissingColumns=True)\n",
    "        except Exception: \n",
    "            pass \n",
    "    \n",
    "    #clean\n",
    "    df = clean_time(df, 'tradingDate')\n",
    "    df = df.withColumnRenamed('tradingDate', 'timeStamp')\n",
    "\n",
    "    #Write to db\n",
    "    data_to_db(df, 'stock_history')\n",
    "    return df\n",
    "\n",
    "# get_stock_history(\"2022-10-01\", \"2022-11-22\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intraday_transaction():   \n",
    "    #Create blank dataframe\n",
    "    df = spark.createDataFrame([], StructType([]))\n",
    "\n",
    "    d = datetime.now()\n",
    "    today = re.sub(\" (.+)\",\"\", str(d))\n",
    "\n",
    "    if d.weekday() > 4: #today is weekend\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                data = requests.get('https://apipubaws.tcbs.com.vn/stock-insight/v1/intraday/{}/his/paging?page={}&size={}&headIndex=-1'.format(ticker, 0, 1000)).json()\n",
    "                pd_df = json_normalize(data['data'])\n",
    "                value=spark.createDataFrame(pd_df)                 \n",
    "                value = value.withColumn('ticker', lit(ticker))\n",
    "                df = df.unionByName(value, allowMissingColumns=True)\n",
    "            except Exception: \n",
    "                pass \n",
    "    else: #today is weekday\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                data = requests.get('https://apipubaws.tcbs.com.vn/stock-insight/v1/intraday/{}/his/paging?page={}&size={}'.format(ticker, 0, 1000)).json()\n",
    "                pd_df = json_normalize(data['data'])\n",
    "                value=spark.createDataFrame(pd_df)     \n",
    "                value = value.withColumn('ticker', lit(ticker))\n",
    "                df = df.unionByName(value, allowMissingColumns=True)\n",
    "            except Exception: \n",
    "                pass \n",
    "    \n",
    "    #Clean\n",
    "    df = df.withColumn('t', concat_ws(' ', lit(today), col('t')))\n",
    "    df = df.withColumnRenamed(\"p\",\"price\")\\\n",
    "            .withColumnRenamed(\"v\",\"volume\")\\\n",
    "            .withColumnRenamed(\"t\",\"timeStamp\")\n",
    "\n",
    "    #Write to db\n",
    "    data_to_db(df, 'listing_companies')\n",
    "    return df\n",
    "    \n",
    "# get_intraday_transaction().show(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listing_companies():\n",
    "\n",
    "    #Create blank dataframe\n",
    "    df = spark.createDataFrame([], StructType([]))\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data = requests.get('https://apipubaws.tcbs.com.vn/tcanalysis/v1/ticker/{}/overview'.format(ticker))\n",
    "            rdd = spark.sparkContext.parallelize([data.text])\n",
    "            value = spark.read.json(rdd)\n",
    "            df = df.unionByName(value, allowMissingColumns=True)\n",
    "        except Exception: \n",
    "            pass  \n",
    "    \n",
    "    #Write to db\n",
    "    data_to_db(df, 'stock_history')\n",
    "    return df\n",
    "\n",
    "# get_listing_companies().show(1000, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"foo\",\"r\") as f:\n",
    "    string = f.read()\n",
    "print( '. '.join(map(lambda s: s.strip().capitalize(), x.split('_'))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
